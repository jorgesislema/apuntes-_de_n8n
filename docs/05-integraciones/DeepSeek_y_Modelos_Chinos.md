# Integraci√≥n con IAs Chinas (DeepSeek, Qwen, Yi)

El ecosistema de IA en China est√° explotando con modelos que rivalizan con GPT-4 a una fracci√≥n del costo. La mayor√≠a de estos modelos han adoptado el est√°ndar de **OpenAI API Compatible**, lo que facilita enormemente su integraci√≥n en n8n.

## üá®üá≥ DeepSeek (DeepSeek-V3 / R1)

DeepSeek ha ganado fama por su rendimiento en c√≥digo y razonamiento (modelo R1) a precios extremadamente bajos.

### C√≥mo conectar en n8n
No necesitas un nodo especial. Usa el nodo **OpenAI Chat Model**.

1. **Credencial:** Crea una nueva credencial de tipo `OpenAI API`.
   - **API Key:** Tu llave de `platform.deepseek.com`.
   - **Base URL:** `https://api.deepseek.com` (¬°Importante!).
2. **Nodo:** `AI Agent` o `Basic LLM Chain`.
   - Conecta el modelo `OpenAI Chat Model`.
   - En el campo **Model Name**, selecciona "Expression" y escribe manualmente: `deepseek-chat` o `deepseek-reasoner`.

### Modelos Disponibles
- `deepseek-chat` (V3): Uso general, r√°pido, barato.
- `deepseek-reasoner` (R1): Modelo de razonamiento (Chain of Thought), ideal para l√≥gica compleja, matem√°ticas y c√≥digo.

---

## üêº Alibaba Qwen (Tongyi Qianwen)

Qwen es uno de los modelos open-source m√°s potentes. Disponible v√≠a Alibaba Cloud (DashScope).

### Conexi√≥n (OpenAI Compatible)
Alibaba ofrece un endpoint compatible.
- **Base URL:** `https://dashscope-intl.aliyuncs.com/compatible-mode/v1`
- **API Key:** Obtener en Alibaba Cloud Console.
- **Model Name:** `qwen-plus`, `qwen-turbo`, `qwen-max`.

---

## 01.AI (Yi)

Modelos con ventanas de contexto gigantes (200k tokens).

- **Base URL:** `https://api.01.ai/v1`
- **Model Name:** `yi-large`, `yi-medium`.

---

## üõ†Ô∏è Uso con HTTP Request (M√©todo Universal)

Si el nodo de OpenAI falla o necesitas par√°metros espec√≠ficos no soportados, usa el nodo `HTTP Request`.

**Configuraci√≥n T√≠pica:**
- **Method:** POST
- **URL:** `https://api.deepseek.com/chat/completions`
- **Authentication:** Header Auth (`Authorization: Bearer sk-tu-clave`).
- **Body (JSON):**
```json
{
  "model": "deepseek-chat",
  "messages": [
    {"role": "system", "content": "Eres un asistente √∫til."},
    {"role": "user", "content": "Hola, ¬øqui√©n eres?"}
  ],
  "temperature": 0.7
}
```

## ‚ö†Ô∏è Consideraciones de Privacidad y Latencia
- **Latencia:** Al estar los servidores en China o regiones asi√°ticas, la latencia puede ser mayor que con OpenAI (EE.UU.).
- **Privacidad:** Revisa los t√©rminos de servicio si manejas datos sensibles (GDPR). Para uso empresarial estricto, considera usar estos modelos v√≠a proveedores como **OpenRouter** o **Groq** (si los alojan), o self-hosted con **Ollama**.

### DeepSeek Local con Ollama
Si quieres privacidad total:
1. Instala Ollama en tu servidor.
2. Ejecuta `ollama run deepseek-r1`.
3. En n8n, usa el nodo **Ollama Chat Model**.
   - Base URL: `http://tu-servidor:11434`.
   - Model: `deepseek-r1`.
