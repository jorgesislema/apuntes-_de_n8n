# OpenAI - Gu√≠a Completa de Integraci√≥n

## ¬øQu√© es OpenAI?

OpenAI es una plataforma de **inteligencia artificial avanzada** que ofrece modelos de lenguaje capaces de entender y generar texto, analizar im√°genes, crear c√≥digo, traducir idiomas y realizar tareas complejas de procesamiento de lenguaje natural. En n8n, permite automatizar procesos que requieren capacidades de IA.

### Concepto T√©cnico
OpenAI funciona mediante:
- **Modelos de lenguaje**: GPT-4, GPT-3.5-turbo para procesamiento de texto
- **Procesamiento de prompts**: Instrucciones espec√≠ficas para obtener resultados deseados
- **API REST**: Interfaz para integraci√≥n con aplicaciones externas
- **Tokens**: Unidades de medida para el procesamiento de texto

## Configuraci√≥n Inicial

### 1. **Obtener API Key**

#### Paso 1: Crear Cuenta
1. Ve a [OpenAI Platform](https://platform.openai.com)
2. Crea una cuenta o inicia sesi√≥n
3. Ve a **API Keys**
4. Clic en **Create new secret key**
5. **¬°IMPORTANTE!** Copia la key inmediatamente (solo se muestra una vez)

#### Paso 2: Configurar Billing
1. Ve a **Billing** ‚Üí **Payment methods**
2. Agrega una tarjeta de cr√©dito
3. Configura l√≠mites de uso (recomendado: $10-20/mes para empezar)

### 2. **Configurar en n8n**

#### M√©todo 1: Credenciales OpenAI
1. **Credentials** ‚Üí **Add Credential**
2. **OpenAI**
3. Pega tu API Key
4. **Save**

#### M√©todo 2: HTTP Request Manual
```javascript
// Headers para HTTP Request
{
  "Authorization": "Bearer {{ $credentials.openai.api_key }}",
  "Content-Type": "application/json"
}
```

## üß† Modelos Disponibles

### 1. **GPT-4 Turbo** (Recomendado)
- **Modelo:** `gpt-4-turbo-preview`
- **Fortalezas:** Mejor razonamiento, m√°s actual, m√°s tokens
- **Costo:** ~$0.01 por 1K tokens input, ~$0.03 por 1K tokens output
- **Uso:** Tareas complejas, an√°lisis, c√≥digo avanzado

### 2. **GPT-3.5 Turbo** (Econ√≥mico)
- **Modelo:** `gpt-3.5-turbo`
- **Fortalezas:** R√°pido, econ√≥mico, eficiente
- **Costo:** ~$0.0015 por 1K tokens input, ~$0.002 por 1K tokens output
- **Uso:** Tareas simples, chatbots, clasificaci√≥n

### 3. **GPT-4 Vision** (Im√°genes)
- **Modelo:** `gpt-4-vision-preview`
- **Fortalezas:** Puede analizar im√°genes
- **Costo:** Variable seg√∫n resoluci√≥n
- **Uso:** An√°lisis de im√°genes, OCR, descripci√≥n visual

## üìù Casos de Uso Comunes

### 1. **Chatbot Inteligente**

#### Configuraci√≥n B√°sica
```json
{
  "model": "gpt-4-turbo-preview",
  "messages": [
    {
      "role": "system",
      "content": "Eres un asistente √∫til y amigable. Responde de manera concisa y profesional."
    },
    {
      "role": "user",
      "content": "{{ $json.mensaje_usuario }}"
    }
  ],
  "max_tokens": 150,
  "temperature": 0.7
}
```

#### Workflow: Webhook ‚Üí OpenAI ‚Üí Respuesta
```javascript
// En nodo Code - Preparar contexto
const conversacion = [
  {
    role: "system",
    content: "Eres un asistente de atenci√≥n al cliente de una empresa de tecnolog√≠a. S√© helpful pero conciso."
  },
  {
    role: "user",
    content: $json.mensaje
  }
];

return [{
  json: {
    messages: conversacion,
    max_tokens: 200,
    temperature: 0.7
  }
}];
```

### 2. **An√°lisis de Sentimientos**

#### Prompt Especializado
```javascript
// En nodo Set - Preparar prompt
const prompt = `Analiza el sentimiento del siguiente texto y clasif√≠calo como POSITIVO, NEGATIVO o NEUTRAL.

Texto: "${$json.comentario}"

Responde en formato JSON:
{
  "sentimiento": "POSITIVO/NEGATIVO/NEUTRAL",
  "confianza": 0.85,
  "razon": "Explicaci√≥n breve"
}`;

return [{
  json: {
    model: "gpt-3.5-turbo",
    messages: [
      {
        role: "user",
        content: prompt
      }
    ],
    max_tokens: 100,
    temperature: 0.3
  }
}];
```

### 3. **Generaci√≥n de Contenido**

#### Blog Posts Autom√°ticos
```javascript
// En nodo Code - Crear prompt para blog
const tema = $json.tema;
const palabrasClave = $json.palabras_clave || [];

const prompt = `Escribe un art√≠culo de blog sobre "${tema}".

Requisitos:
- Longitud: 500-800 palabras
- Tono: Profesional pero accesible
- Incluir palabras clave: ${palabrasClave.join(', ')}
- Estructura: Introducci√≥n, desarrollo, conclusi√≥n
- Incluir call-to-action al final

Formato: Markdown`;

return [{
  json: {
    model: "gpt-4-turbo-preview",
    messages: [
      {
        role: "system",
        content: "Eres un experto copywriter especializado en crear contenido web optimizado."
      },
      {
        role: "user",
        content: prompt
      }
    ],
    max_tokens: 1200,
    temperature: 0.8
  }
}];
```

### 4. **Traducci√≥n Inteligente**

#### Traducci√≥n con Contexto
```javascript
// En nodo Set - Preparar traducci√≥n
const prompt = `Traduce el siguiente texto del ${$json.idioma_origen} al ${$json.idioma_destino}.

Texto original: "${$json.texto}"

Instrucciones:
- Mant√©n el tono y estilo original
- Adapta expresiones culturales cuando sea necesario
- Si hay t√©rminos t√©cnicos, mantenlos apropiados para el idioma destino

Responde solo con la traducci√≥n.`;

return [{
  json: {
    model: "gpt-4-turbo-preview",
    messages: [
      {
        role: "user",
        content: prompt
      }
    ],
    max_tokens: 300,
    temperature: 0.3
  }
}];
```

### 5. **Generaci√≥n de C√≥digo**

#### Asistente de Programaci√≥n
```javascript
// En nodo Code - Generar c√≥digo
const solicitud = $json.solicitud;
const lenguaje = $json.lenguaje || 'JavaScript';

const prompt = `Genera c√≥digo en ${lenguaje} para: ${solicitud}

Requisitos:
- C√≥digo limpio y bien comentado
- Incluir manejo de errores
- Agregar ejemplos de uso
- Explicar la l√≥gica brevemente

Formato:
\`\`\`${lenguaje.toLowerCase()}
// C√≥digo aqu√≠
\`\`\`

Explicaci√≥n: [Explicaci√≥n breve]`;

return [{
  json: {
    model: "gpt-4-turbo-preview",
    messages: [
      {
        role: "system",
        content: "Eres un programador experto que genera c√≥digo limpio y bien documentado."
      },
      {
        role: "user",
        content: prompt
      }
    ],
    max_tokens: 800,
    temperature: 0.4
  }
}];
```

## üõ†Ô∏è T√©cnicas Avanzadas

### 1. **Prompt Engineering**

#### Estructura de Prompt Efectivo
```javascript
const promptEstructurado = `
## ROL
Eres un experto en [√°rea espec√≠fica]

## CONTEXTO
[Informaci√≥n relevante sobre la situaci√≥n]

## TAREA
[Descripci√≥n clara de lo que necesitas]

## FORMATO
[C√≥mo quieres que responda]

## EJEMPLO
[Ejemplo de respuesta esperada]

## RESTRICCIONES
- [Limitaci√≥n 1]
- [Limitaci√≥n 2]
- [Limitaci√≥n 3]
`;
```

#### T√©cnicas de Mejora
```javascript
// 1. Few-shot learning (ejemplos)
const prompt = `Clasifica estos comentarios como positivos o negativos:

Ejemplo 1: "Me encanta este producto" ‚Üí Positivo
Ejemplo 2: "Terrible servicio al cliente" ‚Üí Negativo
Ejemplo 3: "Funciona bien pero podr√≠a mejorar" ‚Üí Neutral

Ahora clasifica: "${$json.comentario}"`;

// 2. Chain of thought (razonamiento paso a paso)
const prompt = `Resuelve este problema paso a paso:

Problema: ${$json.problema}

Paso 1: Identifica los datos dados
Paso 2: Determina qu√© necesitas encontrar
Paso 3: Elige el m√©todo apropiado
Paso 4: Resuelve paso a paso
Paso 5: Verifica el resultado`;

// 3. Role playing (juego de roles)
const prompt = `Act√∫a como un experto en marketing digital con 10 a√±os de experiencia. 
Analiza esta campa√±a y da recomendaciones espec√≠ficas y accionables.

Campa√±a: ${$json.descripcion_campana}`;
```

### 2. **Manejo de Tokens**

#### Optimizaci√≥n de Costos
```javascript
// En nodo Code - Calcular tokens aproximados
const contarTokens = (texto) => {
  // Aproximaci√≥n: 1 token ‚âà 4 caracteres en ingl√©s
  return Math.ceil(texto.length / 4);
};

const prompt = $json.prompt;
const tokensEstimados = contarTokens(prompt);

// Ajustar max_tokens seg√∫n el prompt
const maxTokens = Math.min(tokensEstimados + 200, 1000);

return [{
  json: {
    model: "gpt-3.5-turbo",
    messages: [{ role: "user", content: prompt }],
    max_tokens: maxTokens,
    temperature: 0.7
  }
}];
```

#### Truncado Inteligente
```javascript
// Truncar contenido largo manteniendo contexto
const truncarTexto = (texto, maxTokens = 3000) => {
  const maxChars = maxTokens * 4; // Aproximaci√≥n
  
  if (texto.length <= maxChars) {
    return texto;
  }
  
  // Truncar pero mantener p√°rrafos completos
  const truncado = texto.substring(0, maxChars);
  const ultimoPunto = truncado.lastIndexOf('.');
  
  return ultimoPunto > maxChars * 0.8 ? 
    truncado.substring(0, ultimoPunto + 1) : 
    truncado;
};
```

### 3. **Prompts Din√°micos**

#### Generaci√≥n Basada en Contexto
```javascript
// En nodo Code - Crear prompt din√°mico
const crearPrompt = (usuario, contexto) => {
  const tipoUsuario = usuario.tipo || 'general';
  const historial = contexto.historial || [];
  
  let systemPrompt = "Eres un asistente √∫til.";
  
  switch (tipoUsuario) {
    case 'tecnico':
      systemPrompt = "Eres un experto t√©cnico. Usa terminolog√≠a precisa y da detalles t√©cnicos.";
      break;
    case 'principiante':
      systemPrompt = "Eres un tutor paciente. Explica conceptos de manera simple y con ejemplos.";
      break;
    case 'ejecutivo':
      systemPrompt = "Eres un consultor de negocios. Enf√≥cate en impacto comercial y ROI.";
      break;
  }
  
  // Agregar contexto del historial
  if (historial.length > 0) {
    const contextoHistorial = historial
      .slice(-3) // √öltimas 3 interacciones
      .map(h => `Usuario: ${h.pregunta}\nAsistente: ${h.respuesta}`)
      .join('\n\n');
    
    systemPrompt += `\n\nContexto de conversaci√≥n previa:\n${contextoHistorial}`;
  }
  
  return systemPrompt;
};
```

### 4. **Validaci√≥n y Post-procesamiento**

#### Validar Respuestas
```javascript
// En nodo Code - Validar respuesta de OpenAI
const validarRespuesta = (respuesta) => {
  const errores = [];
  
  // Verificar longitud
  if (respuesta.length < 10) {
    errores.push('Respuesta demasiado corta');
  }
  
  // Verificar si es JSON v√°lido (si se esperaba JSON)
  if ($json.formato === 'json') {
    try {
      JSON.parse(respuesta);
    } catch (e) {
      errores.push('Respuesta no es JSON v√°lido');
    }
  }
  
  // Verificar palabras prohibidas
  const palabrasProhibidas = ['error', 'no puedo', 'no s√©'];
  const contieneProhibidas = palabrasProhibidas.some(palabra => 
    respuesta.toLowerCase().includes(palabra)
  );
  
  if (contieneProhibidas) {
    errores.push('Respuesta contiene palabras prohibidas');
  }
  
  return {
    valida: errores.length === 0,
    errores: errores
  };
};
```

#### Formatear Respuestas
```javascript
// En nodo Code - Formatear respuesta
const formatearRespuesta = (respuesta, formato) => {
  switch (formato) {
    case 'markdown':
      return respuesta.replace(/\n/g, '  \n'); // Markdown line breaks
    
    case 'html':
      return respuesta
        .replace(/\n/g, '<br>')
        .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
    
    case 'json':
      try {
        return JSON.parse(respuesta);
      } catch (e) {
        return { error: 'Respuesta no es JSON v√°lido', raw: respuesta };
      }
    
    case 'lista':
      return respuesta
        .split('\n')
        .filter(linea => linea.trim())
        .map(linea => linea.replace(/^-\s*/, ''));
    
    default:
      return respuesta;
  }
};
```

## üìä Monitoreo y Optimizaci√≥n

### 1. **Tracking de Costos**

#### Calcular Costo por Request
```javascript
// En nodo Code - Calcular costo
const calcularCosto = (modelo, tokensInput, tokensOutput) => {
  const precios = {
    'gpt-4-turbo-preview': { input: 0.01, output: 0.03 },
    'gpt-3.5-turbo': { input: 0.0015, output: 0.002 },
    'gpt-4-vision-preview': { input: 0.01, output: 0.03 }
  };
  
  const precio = precios[modelo] || precios['gpt-3.5-turbo'];
  
  const costoInput = (tokensInput / 1000) * precio.input;
  const costoOutput = (tokensOutput / 1000) * precio.output;
  
  return {
    costoInput: costoInput,
    costoOutput: costoOutput,
    costoTotal: costoInput + costoOutput,
    tokensInput: tokensInput,
    tokensOutput: tokensOutput
  };
};
```

### 2. **M√©tricas de Performance**

#### Tracking de Respuestas
```javascript
// En nodo Code - M√©tricas de respuesta
const analizarRespuesta = (respuesta, tiempoInicio) => {
  const tiempoFin = Date.now();
  const tiempoRespuesta = tiempoFin - tiempoInicio;
  
  return {
    tiempoRespuesta: tiempoRespuesta,
    longitudRespuesta: respuesta.length,
    palabras: respuesta.split(' ').length,
    calidad: respuesta.includes('no puedo') ? 'baja' : 'alta',
    timestamp: new Date().toISOString()
  };
};
```

## üö® Manejo de Errores

### 1. **Errores Comunes**

#### Rate Limiting
```javascript
// En nodo Code - Manejo de rate limiting
const manejarRateLimit = async (funcion, maxReintentos = 3) => {
  for (let intento = 0; intento < maxReintentos; intento++) {
    try {
      return await funcion();
    } catch (error) {
      if (error.response?.status === 429) {
        const delay = Math.pow(2, intento) * 1000; // Exponential backoff
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }
      throw error;
    }
  }
  throw new Error('Rate limit excedido despu√©s de varios intentos');
};
```

#### Timeout Handling
```javascript
// En nodo Code - Timeout personalizado
const conTimeout = (promesa, timeout = 30000) => {
  return Promise.race([
    promesa,
    new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Timeout')), timeout)
    )
  ]);
};
```

### 2. **Fallbacks Inteligentes**

#### Modelo de Respaldo
```javascript
// En nodo Code - Fallback a modelo m√°s simple
const procesarConFallback = async (prompt) => {
  try {
    // Intentar con GPT-4 primero
    return await openai.chat.completions.create({
      model: "gpt-4-turbo-preview",
      messages: [{ role: "user", content: prompt }],
      max_tokens: 200
    });
  } catch (error) {
    console.log('GPT-4 fall√≥, usando GPT-3.5');
    
    // Fallback a GPT-3.5
    return await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [{ role: "user", content: prompt }],
      max_tokens: 200
    });
  }
};
```

## üìã Checklist de Buenas Pr√°cticas

### ‚úÖ Configuraci√≥n
- [ ] API Key segura (no hardcodeada)
- [ ] L√≠mites de billing configurados
- [ ] Modelo apropiado para cada caso de uso
- [ ] Timeouts configurados

### ‚úÖ Prompts
- [ ] Prompts claros y espec√≠ficos
- [ ] Contexto suficiente pero no excesivo
- [ ] Formato de respuesta especificado
- [ ] Ejemplos cuando sea necesario

### ‚úÖ Performance
- [ ] Optimizaci√≥n de tokens
- [ ] Cach√© para respuestas repetitivas
- [ ] Batch processing cuando sea posible
- [ ] Monitoreo de costos

### ‚úÖ Manejo de Errores
- [ ] Retry logic para failures temporales
- [ ] Fallbacks a modelos alternativos
- [ ] Validaci√≥n de respuestas
- [ ] Logging para debugging

## üéì Ejercicios Pr√°cticos

### Ejercicio 1: Chatbot Especializado
Crea un chatbot que:
1. Identifique el tipo de consulta (soporte, ventas, general)
2. Use prompts espec√≠ficos para cada tipo
3. Mantenga contexto de conversaci√≥n
4. Escale a humano cuando sea necesario

### Ejercicio 2: Analizador de Feedback
Crea un sistema que:
1. Analice comentarios de clientes
2. Extraiga temas principales
3. Clasifique por urgencia
4. Genere respuestas sugeridas

### Ejercicio 3: Generador de Contenido
Crea un workflow que:
1. Genere t√≠tulos para blog posts
2. Cree outlines detallados
3. Escriba contenido completo
4. Optimice para SEO

---

**Recuerda:** OpenAI es una herramienta poderosa que requiere uso correcto y responsable. Experimenta con diferentes prompts, modelos y configuraciones para encontrar lo que funciona mejor para tu caso de uso espec√≠fico.
