# üíæ Backup y Restore para n8n

> **Gu√≠a completa para proteger y recuperar tus datos de n8n - Nunca pierdas tu trabajo**

## üìã √çndice

- [üåü Importancia del Backup](#-importancia-del-backup)
- [üìÇ ¬øQu√© Hacer Backup?](#-qu√©-hacer-backup)
- [üîÑ Estrategias de Backup](#-estrategias-de-backup)
- [üíæ Backup Manual](#-backup-manual)
- [‚ö° Backup Automatizado](#-backup-automatizado)
- [‚òÅÔ∏è Backup en la Nube](#Ô∏è-backup-en-la-nube)
- [üîÑ Restore y Recuperaci√≥n](#-restore-y-recuperaci√≥n)
- [üß™ Testing de Backups](#-testing-de-backups)
- [üìä Monitoreo y Alertas](#-monitoreo-y-alertas)

---

## üåü Importancia del Backup

### üí• **Escenarios de P√©rdida**

- **üñ•Ô∏è Fallo de hardware**: Disco duro se da√±a
- **üî• Desastre natural**: Incendio, inundaci√≥n, etc.
- **üë®‚Äçüíª Error humano**: Borrado accidental de datos
- **ü¶† Malware/Ransomware**: Cifrado malicioso de datos
- **‚òÅÔ∏è Fallo del proveedor**: VPS/cloud provider tiene problemas
- **üîß Actualizaci√≥n fallida**: Update corrompe la instalaci√≥n
- **üíª Migraci√≥n**: Cambio de servidor o provider

### üìä **Estad√≠sticas de P√©rdida de Datos**

| Causa | % de Casos | Tiempo de Recuperaci√≥n |
|-------|------------|----------------------|
| **Error humano** | 40% | 2-8 horas |
| **Fallo de hardware** | 35% | 4-24 horas |
| **Malware** | 15% | 1-7 d√≠as |
| **Desastre natural** | 10% | 1-30 d√≠as |

### üí∞ **Costo de NO tener Backup**

- **‚è±Ô∏è Tiempo perdido**: Recrear workflows manualmente
- **üíº P√©rdida de negocio**: Automaciones interrumpidas
- **üò∞ Estr√©s**: Presi√≥n para recuperar datos cr√≠ticos
- **üîß Costo de recuperaci√≥n**: Servicios especializados ($1000-10000+)

---

## üìÇ ¬øQu√© Hacer Backup?

### üóÇÔ∏è **Datos Esenciales de n8n**

```
~/.n8n/                          # Directorio principal
‚îú‚îÄ‚îÄ config/                      # Configuraciones
‚îÇ   ‚îî‚îÄ‚îÄ config.json             # Configuraci√≥n principal
‚îú‚îÄ‚îÄ credentials/                 # Credenciales (CR√çTICO)
‚îÇ   ‚îî‚îÄ‚îÄ *.json                  # Archivos de credenciales encriptadas
‚îú‚îÄ‚îÄ workflows/                   # Workflows (CR√çTICO)
‚îÇ   ‚îî‚îÄ‚îÄ *.json                  # Definiciones de workflows
‚îú‚îÄ‚îÄ nodes/                       # Nodos personalizados
‚îÇ   ‚îî‚îÄ‚îÄ custom-nodes/           # C√≥digo de nodos custom
‚îú‚îÄ‚îÄ backups/                     # Backups internos de n8n
‚îÇ   ‚îú‚îÄ‚îÄ workflows/              # Exports autom√°ticos
‚îÇ   ‚îî‚îÄ‚îÄ credentials/            # Exports de credenciales
‚îî‚îÄ‚îÄ logs/                        # Logs (opcional)
    ‚îî‚îÄ‚îÄ n8n.log                 # Archivos de log
```

### üóÑÔ∏è **Base de Datos** (si usas PostgreSQL/MySQL)

```sql
-- Estructura de base de datos n8n
-- Tablas cr√≠ticas:
execution_entity        -- Historial de ejecuciones
workflow_entity         -- Definiciones de workflows
credentials_entity      -- Credenciales encriptadas
user_entity            -- Usuarios (si usas multi-user)
settings                -- Configuraciones globales
```

### ‚öôÔ∏è **Configuraciones del Sistema**

```
/opt/n8n/                       # Directorio de instalaci√≥n
‚îú‚îÄ‚îÄ docker-compose.yml         # Configuraci√≥n Docker
‚îú‚îÄ‚îÄ .env                       # Variables de entorno (CR√çTICO)
‚îú‚îÄ‚îÄ nginx/                     # Configuraci√≥n del proxy
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf             # Configuraci√≥n de Nginx
‚îú‚îÄ‚îÄ ssl/                       # Certificados SSL
‚îÇ   ‚îú‚îÄ‚îÄ cert.pem              # Certificado p√∫blico
‚îÇ   ‚îî‚îÄ‚îÄ key.pem               # Clave privada (CR√çTICO)
‚îî‚îÄ‚îÄ scripts/                   # Scripts de mantenimiento
    ‚îú‚îÄ‚îÄ backup.sh             # Scripts de backup
    ‚îî‚îÄ‚îÄ restore.sh            # Scripts de restore
```

---

## üîÑ Estrategias de Backup

### üìä **Tipos de Backup**

| Tipo | Descripci√≥n | Frecuencia | Ventajas | Desventajas |
|------|-------------|-----------|----------|-------------|
| **üîÑ Completo** | Todo el dataset | Semanal | Simple, completo | Lento, ocupa espacio |
| **üìà Incremental** | Solo cambios desde √∫ltimo backup | Diario | R√°pido, eficiente | Restore complejo |
| **üìä Diferencial** | Cambios desde √∫ltimo completo | Diario | Balance eficiencia/simplicidad | Crece con el tiempo |
| **üîÑ Snapshot** | Estado espec√≠fico en el tiempo | Por evento | Instant√°neo | Depende del storage |

### üéØ **Estrategia 3-2-1**

```
3 Copias de los datos cr√≠ticos
‚îú‚îÄ‚îÄ 1 Copia primaria (producci√≥n)
‚îú‚îÄ‚îÄ 1 Copia local (backup local)
‚îî‚îÄ‚îÄ 1 Copia remota (backup offsite)

2 Tipos de media diferentes
‚îú‚îÄ‚îÄ Local: SSD/HDD
‚îî‚îÄ‚îÄ Remota: Cloud storage

1 Copia geogr√°ficamente separada
‚îî‚îÄ‚îÄ Cloud provider diferente o localizaci√≥n f√≠sica distinta
```

### ‚è∞ **Cronograma Recomendado**

| Componente | Frecuencia | Retenci√≥n | M√©todo |
|------------|-----------|-----------|--------|
| **Workflows** | Cada 4 horas | 30 d√≠as | Incremental |
| **Credenciales** | Diario | 90 d√≠as | Completo |
| **Base de datos** | Diario | 30 d√≠as | Completo |
| **Configuraciones** | Semanal | 180 d√≠as | Completo |
| **Sistema completo** | Semanal | 30 d√≠as | Snapshot |

---

## üíæ Backup Manual

### üìÅ **Backup de Datos n8n**

```bash
#!/bin/bash
# backup-manual.sh - Backup manual completo

# Configuraci√≥n
BACKUP_DIR="/backups/n8n"
DATE=$(date +%Y%m%d_%H%M%S)
N8N_DATA_DIR="$HOME/.n8n"
DOCKER_PROJECT="n8n"

echo "üîÑ Iniciando backup manual de n8n..."

# Crear directorio de backup
mkdir -p "$BACKUP_DIR/$DATE"

# 1. Parar n8n temporalmente para consistencia
echo "‚è∏Ô∏è Pausando servicios..."
docker-compose -p $DOCKER_PROJECT stop n8n

# 2. Backup de datos n8n
echo "üíæ Backup de datos n8n..."
tar -czf "$BACKUP_DIR/$DATE/n8n-data.tar.gz" -C "$(dirname $N8N_DATA_DIR)" "$(basename $N8N_DATA_DIR)"

# 3. Backup de workflows (export JSON)
echo "üìã Export de workflows..."
if [ -d "$N8N_DATA_DIR/workflows" ]; then
    cp -r "$N8N_DATA_DIR/workflows" "$BACKUP_DIR/$DATE/workflows-export"
fi

# 4. Backup de configuraciones Docker
echo "‚öôÔ∏è Backup de configuraciones..."
tar -czf "$BACKUP_DIR/$DATE/config.tar.gz" docker-compose.yml .env nginx/ ssl/

# 5. Backup de base de datos (si es PostgreSQL)
if docker-compose -p $DOCKER_PROJECT ps postgres &>/dev/null; then
    echo "üóÑÔ∏è Backup de base de datos PostgreSQL..."
    docker-compose -p $DOCKER_PROJECT exec postgres pg_dump -U n8nuser n8n | gzip > "$BACKUP_DIR/$DATE/postgres-dump.sql.gz"
fi

# 6. Crear metadata del backup
echo "üìù Creando metadata..."
cat > "$BACKUP_DIR/$DATE/backup-info.json" << EOF
{
  "backup_date": "$(date -Iseconds)",
  "backup_type": "manual",
  "n8n_version": "$(docker-compose -p $DOCKER_PROJECT exec n8n n8n --version 2>/dev/null | head -1)",
  "system_info": {
    "hostname": "$(hostname)",
    "os": "$(uname -a)",
    "docker_version": "$(docker --version)"
  },
  "backup_size": "$(du -sh $BACKUP_DIR/$DATE | cut -f1)",
  "components": [
    "n8n-data",
    "workflows-export", 
    "docker-config",
    "postgres-database"
  ]
}
EOF

# 7. Reiniciar servicios
echo "‚ñ∂Ô∏è Reiniciando servicios..."
docker-compose -p $DOCKER_PROJECT start n8n

# 8. Verificar que n8n est√© funcionando
sleep 10
if curl -f http://localhost:5678/healthz &>/dev/null; then
    echo "‚úÖ n8n est√° funcionando correctamente"
else
    echo "‚ö†Ô∏è ADVERTENCIA: n8n podr√≠a no estar respondiendo"
fi

# 9. Comprimir backup completo
echo "üì¶ Comprimiendo backup completo..."
cd "$BACKUP_DIR"
tar -czf "n8n-backup-$DATE.tar.gz" "$DATE/"
rm -rf "$DATE/"

echo "üéâ Backup completado: $BACKUP_DIR/n8n-backup-$DATE.tar.gz"
echo "üìä Tama√±o del backup: $(du -sh $BACKUP_DIR/n8n-backup-$DATE.tar.gz | cut -f1)"
```

### üìã **Backup Espec√≠fico de Workflows**

```bash
#!/bin/bash
# backup-workflows.sh - Solo workflows

N8N_URL="http://localhost:5678"
BACKUP_DIR="/backups/workflows"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p "$BACKUP_DIR"

echo "üìã Exportando workflows..."

# Usar n8n CLI para export
docker-compose exec n8n n8n export:workflow --all --output="/home/node/export-$DATE.json"

# Copiar export al host
docker cp n8n:/home/node/export-$DATE.json "$BACKUP_DIR/workflows-$DATE.json"

# Limpiar archivo temporal
docker-compose exec n8n rm "/home/node/export-$DATE.json"

echo "‚úÖ Workflows exportados: $BACKUP_DIR/workflows-$DATE.json"
```

---

## ‚ö° Backup Automatizado

### üîÑ **Script de Backup Automatizado**

```bash
#!/bin/bash
# auto-backup.sh - Sistema completo de backup automatizado

# ========================================
# Configuraci√≥n
# ========================================
BACKUP_BASE_DIR="/backups/n8n"
RETENTION_DAYS=30
MAX_BACKUPS=10
N8N_DATA_DIR="$HOME/.n8n"
DOCKER_PROJECT="n8n"
LOG_FILE="/var/log/n8n-backup.log"

# Configuraci√≥n de notificaciones (opcional)
NOTIFY_EMAIL="admin@yourdomain.com"
SLACK_WEBHOOK=""

# ========================================
# Funciones
# ========================================
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

notify() {
    local message="$1"
    local level="$2"  # INFO, WARNING, ERROR
    
    log "$level: $message"
    
    # Email notification (opcional)
    if [ ! -z "$NOTIFY_EMAIL" ]; then
        echo "$message" | mail -s "n8n Backup $level" "$NOTIFY_EMAIL" 2>/dev/null || true
    fi
    
    # Slack notification (opcional)
    if [ ! -z "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"üîÑ n8n Backup $level: $message\"}" \
            "$SLACK_WEBHOOK" 2>/dev/null || true
    fi
}

cleanup_old_backups() {
    log "üóëÔ∏è Limpiando backups antiguos..."
    
    # Eliminar backups m√°s antiguos que RETENTION_DAYS
    find "$BACKUP_BASE_DIR" -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete
    
    # Mantener solo MAX_BACKUPS m√°s recientes
    ls -t "$BACKUP_BASE_DIR"/*.tar.gz 2>/dev/null | tail -n +$((MAX_BACKUPS + 1)) | xargs rm -f
    
    log "‚úÖ Limpieza completada"
}

check_disk_space() {
    local required_space_gb=5  # GB m√≠nimos requeridos
    local available_space=$(df "$BACKUP_BASE_DIR" | awk 'NR==2 {print int($4/1024/1024)}')
    
    if [ "$available_space" -lt "$required_space_gb" ]; then
        notify "Espacio insuficiente para backup: ${available_space}GB disponibles, ${required_space_gb}GB requeridos" "ERROR"
        return 1
    fi
    
    log "üíæ Espacio disponible: ${available_space}GB"
    return 0
}

backup_database() {
    local backup_dir="$1"
    
    log "üóÑÔ∏è Iniciando backup de base de datos..."
    
    if docker-compose -p $DOCKER_PROJECT ps postgres &>/dev/null; then
        # PostgreSQL backup
        docker-compose -p $DOCKER_PROJECT exec -T postgres pg_dump -U n8nuser n8n | gzip > "$backup_dir/postgres-dump.sql.gz"
        
        if [ ${PIPESTATUS[0]} -eq 0 ]; then
            log "‚úÖ Backup PostgreSQL completado"
        else
            notify "Error en backup de PostgreSQL" "ERROR"
            return 1
        fi
    elif docker-compose -p $DOCKER_PROJECT ps mysql &>/dev/null; then
        # MySQL backup
        docker-compose -p $DOCKER_PROJECT exec -T mysql mysqldump -u n8nuser -p n8n | gzip > "$backup_dir/mysql-dump.sql.gz"
        
        if [ ${PIPESTATUS[0]} -eq 0 ]; then
            log "‚úÖ Backup MySQL completado"
        else
            notify "Error en backup de MySQL" "ERROR"
            return 1
        fi
    else
        log "‚ÑπÔ∏è No se detect√≥ base de datos externa (usando SQLite)"
    fi
    
    return 0
}

# ========================================
# Script Principal
# ========================================
main() {
    local start_time=$(date +%s)
    local date_stamp=$(date +%Y%m%d_%H%M%S)
    local backup_dir="$BACKUP_BASE_DIR/$date_stamp"
    local backup_file="$BACKUP_BASE_DIR/n8n-backup-$date_stamp.tar.gz"
    
    log "üöÄ Iniciando backup automatizado de n8n"
    
    # Verificar prerrequisitos
    if ! check_disk_space; then
        exit 1
    fi
    
    mkdir -p "$backup_dir"
    
    # 1. Parar servicios para garantizar consistencia
    log "‚è∏Ô∏è Pausando servicios n8n..."
    if ! docker-compose -p $DOCKER_PROJECT stop n8n; then
        notify "Error pausando servicios n8n" "ERROR"
        exit 1
    fi
    
    # 2. Backup de datos n8n
    log "üíæ Backup de datos n8n..."
    if tar -czf "$backup_dir/n8n-data.tar.gz" -C "$(dirname $N8N_DATA_DIR)" "$(basename $N8N_DATA_DIR)" 2>/dev/null; then
        log "‚úÖ Backup de datos n8n completado"
    else
        notify "Error en backup de datos n8n" "ERROR"
        docker-compose -p $DOCKER_PROJECT start n8n
        exit 1
    fi
    
    # 3. Export de workflows
    log "üìã Export de workflows..."
    docker-compose -p $DOCKER_PROJECT start n8n
    sleep 15  # Esperar que n8n inicie
    
    docker-compose -p $DOCKER_PROJECT exec -T n8n n8n export:workflow --all --output="/tmp/workflows-export.json" 2>/dev/null
    docker cp "${DOCKER_PROJECT}_n8n_1:/tmp/workflows-export.json" "$backup_dir/workflows-export.json" 2>/dev/null || log "‚ö†Ô∏è No se pudieron exportar workflows"
    
    # 4. Backup de configuraciones
    log "‚öôÔ∏è Backup de configuraciones..."
    tar -czf "$backup_dir/config.tar.gz" docker-compose.yml .env nginx/ ssl/ scripts/ 2>/dev/null || true
    
    # 5. Backup de base de datos
    backup_database "$backup_dir"
    
    # 6. Crear metadata
    log "üìù Creando metadata..."
    cat > "$backup_dir/backup-info.json" << EOF
{
  "backup_date": "$(date -Iseconds)",
  "backup_type": "automated",
  "retention_days": $RETENTION_DAYS,
  "n8n_version": "$(docker-compose -p $DOCKER_PROJECT exec -T n8n n8n --version 2>/dev/null | head -1 | tr -d '\r')",
  "system_info": {
    "hostname": "$(hostname)",
    "os": "$(uname -a)",
    "docker_version": "$(docker --version)",
    "backup_script_version": "1.0"
  }
}
EOF
    
    # 7. Comprimir backup final
    log "üì¶ Comprimiendo backup final..."
    cd "$BACKUP_BASE_DIR"
    tar -czf "n8n-backup-$date_stamp.tar.gz" "$date_stamp/"
    rm -rf "$date_stamp/"
    
    # 8. Verificar integridad del backup
    log "üîç Verificando integridad..."
    if tar -tzf "$backup_file" >/dev/null 2>&1; then
        local backup_size=$(du -sh "$backup_file" | cut -f1)
        log "‚úÖ Backup √≠ntegro: $backup_size"
    else
        notify "Error: Backup corrupto" "ERROR"
        exit 1
    fi
    
    # 9. Limpiar backups antiguos
    cleanup_old_backups
    
    # 10. Verificar que n8n est√© funcionando
    sleep 10
    if curl -f http://localhost:5678/healthz &>/dev/null; then
        log "‚úÖ n8n funcionando correctamente"
    else
        notify "ADVERTENCIA: n8n podr√≠a no estar respondiendo" "WARNING"
    fi
    
    # Estad√≠sticas finales
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local backup_size=$(du -sh "$backup_file" | cut -f1)
    
    notify "Backup completado exitosamente en ${duration}s. Tama√±o: $backup_size" "INFO"
}

# Ejecutar script principal
main "$@"
```

### ‚è∞ **Configurar Cron**

```bash
# Instalar el script
sudo cp auto-backup.sh /opt/n8n-backup.sh
sudo chmod +x /opt/n8n-backup.sh

# Configurar crontab para backup diario a las 2 AM
(crontab -l 2>/dev/null; echo "0 2 * * * /opt/n8n-backup.sh >> /var/log/n8n-backup.log 2>&1") | crontab -

# Backup cada 4 horas (m√°s frecuente)
(crontab -l 2>/dev/null; echo "0 */4 * * * /opt/n8n-backup.sh >> /var/log/n8n-backup.log 2>&1") | crontab -

# Backup semanal completo los domingos
(crontab -l 2>/dev/null; echo "0 1 * * 0 /opt/n8n-backup-weekly.sh >> /var/log/n8n-backup.log 2>&1") | crontab -

# Ver crontab actual
crontab -l
```

---

## ‚òÅÔ∏è Backup en la Nube

### üå©Ô∏è **AWS S3 Integration**

```bash
#!/bin/bash
# backup-s3.sh - Backup a Amazon S3

# Configuraci√≥n AWS
S3_BUCKET="my-n8n-backups"
S3_REGION="us-east-1"
AWS_PROFILE="default"

# Configuraci√≥n local
LOCAL_BACKUP_DIR="/backups/n8n"
RETENTION_CLOUD=90  # d√≠as

sync_to_s3() {
    local local_backup="$1"
    local s3_key="n8n-backups/$(basename $local_backup)"
    
    log "‚òÅÔ∏è Subiendo backup a S3..."
    
    # Subir archivo
    aws s3 cp "$local_backup" "s3://$S3_BUCKET/$s3_key" \
        --region "$S3_REGION" \
        --profile "$AWS_PROFILE" \
        --storage-class STANDARD_IA
    
    if [ $? -eq 0 ]; then
        log "‚úÖ Backup subido a S3: $s3_key"
        
        # Configurar lifecycle para eliminar despu√©s de X d√≠as
        aws s3api put-object-tagging \
            --bucket "$S3_BUCKET" \
            --key "$s3_key" \
            --tagging "TagSet=[{Key=retention,Value=${RETENTION_CLOUD}d}]" \
            --region "$S3_REGION" \
            --profile "$AWS_PROFILE"
    else
        notify "Error subiendo backup a S3" "ERROR"
        return 1
    fi
    
    return 0
}

cleanup_s3_old_backups() {
    log "üóëÔ∏è Limpiando backups antiguos en S3..."
    
    # Listar y eliminar backups antiguos
    aws s3 ls "s3://$S3_BUCKET/n8n-backups/" \
        --region "$S3_REGION" \
        --profile "$AWS_PROFILE" | \
    while read -r line; do
        createDate=$(echo "$line" | awk '{print $1" "$2}')
        createDate=$(date -d "$createDate" +%s)
        olderThan=$(date -d "-${RETENTION_CLOUD} days" +%s)
        
        if [[ $createDate -lt $olderThan ]]; then
            fileName=$(echo "$line" | awk '{$1=$2=$3=""; print $0}' | sed 's/^[ \t]*//')
            if [[ $fileName != "" ]]; then
                aws s3 rm "s3://$S3_BUCKET/n8n-backups/$fileName" \
                    --region "$S3_REGION" \
                    --profile "$AWS_PROFILE"
                log "üóëÔ∏è Eliminado backup antiguo: $fileName"
            fi
        fi
    done
}
```

### üìä **Google Drive Integration**

```bash
#!/bin/bash
# backup-gdrive.sh - Backup a Google Drive usando rclone

# Configurar rclone primero:
# rclone config

GDRIVE_REMOTE="gdrive"
GDRIVE_FOLDER="n8n-backups"

sync_to_gdrive() {
    local local_backup="$1"
    
    log "‚òÅÔ∏è Subiendo backup a Google Drive..."
    
    # Subir archivo
    rclone copy "$local_backup" "$GDRIVE_REMOTE:$GDRIVE_FOLDER" \
        --progress \
        --transfers 4 \
        --checkers 8
    
    if [ $? -eq 0 ]; then
        log "‚úÖ Backup subido a Google Drive"
    else
        notify "Error subiendo backup a Google Drive" "ERROR"
        return 1
    fi
    
    return 0
}

cleanup_gdrive_old_backups() {
    log "üóëÔ∏è Limpiando backups antiguos en Google Drive..."
    
    # Eliminar archivos m√°s antiguos que X d√≠as
    rclone delete "$GDRIVE_REMOTE:$GDRIVE_FOLDER" \
        --min-age "${RETENTION_CLOUD}d" \
        --dry-run  # Quitar para ejecutar realmente
}
```

### üîÑ **Backup Multi-Cloud**

```bash
#!/bin/bash
# backup-multi-cloud.sh - Backup a m√∫ltiples proveedores

backup_to_clouds() {
    local local_backup="$1"
    local success=0
    local total=0
    
    log "üåê Iniciando backup multi-cloud..."
    
    # AWS S3
    if [ ! -z "$S3_BUCKET" ]; then
        total=$((total + 1))
        if sync_to_s3 "$local_backup"; then
            success=$((success + 1))
        fi
    fi
    
    # Google Drive
    if command -v rclone &> /dev/null; then
        total=$((total + 1))
        if sync_to_gdrive "$local_backup"; then
            success=$((success + 1))
        fi
    fi
    
    # Dropbox (usando rclone)
    if rclone listremotes | grep -q "dropbox:"; then
        total=$((total + 1))
        if rclone copy "$local_backup" "dropbox:n8n-backups"; then
            success=$((success + 1))
            log "‚úÖ Backup subido a Dropbox"
        else
            log "‚ùå Error subiendo a Dropbox"
        fi
    fi
    
    # Resumen
    log "üìä Backup cloud: $success/$total proveedores exitosos"
    
    if [ $success -eq 0 ]; then
        notify "CR√çTICO: Fall√≥ backup en todos los proveedores cloud" "ERROR"
        return 1
    elif [ $success -lt $total ]; then
        notify "ADVERTENCIA: Backup fall√≥ en algunos proveedores ($success/$total)" "WARNING"
    else
        log "‚úÖ Backup exitoso en todos los proveedores cloud"
    fi
    
    return 0
}
```

---

## üîÑ Restore y Recuperaci√≥n

### üì¶ **Restore Completo**

```bash
#!/bin/bash
# restore.sh - Restauraci√≥n completa de n8n

# Configuraci√≥n
BACKUP_FILE="$1"
RESTORE_DIR="/tmp/n8n-restore-$(date +%s)"
N8N_DATA_DIR="$HOME/.n8n"
DOCKER_PROJECT="n8n"

if [ -z "$BACKUP_FILE" ]; then
    echo "‚ùå Uso: $0 <backup-file.tar.gz>"
    echo "üìÅ Backups disponibles:"
    ls -la /backups/n8n/n8n-backup-*.tar.gz 2>/dev/null || echo "No hay backups disponibles"
    exit 1
fi

restore_backup() {
    log "üîÑ Iniciando restauraci√≥n desde: $BACKUP_FILE"
    
    # Verificar archivo existe
    if [ ! -f "$BACKUP_FILE" ]; then
        log "‚ùå Archivo de backup no encontrado: $BACKUP_FILE"
        exit 1
    fi
    
    # Crear directorio temporal
    mkdir -p "$RESTORE_DIR"
    
    # Extraer backup
    log "üì¶ Extrayendo backup..."
    tar -xzf "$BACKUP_FILE" -C "$RESTORE_DIR"
    
    if [ $? -ne 0 ]; then
        log "‚ùå Error extrayendo backup"
        exit 1
    fi
    
    # Encontrar directorio de backup
    BACKUP_CONTENT_DIR=$(find "$RESTORE_DIR" -mindepth 1 -maxdepth 1 -type d | head -1)
    
    if [ -z "$BACKUP_CONTENT_DIR" ]; then
        log "‚ùå No se encontr√≥ contenido del backup"
        exit 1
    fi
    
    # Mostrar informaci√≥n del backup
    if [ -f "$BACKUP_CONTENT_DIR/backup-info.json" ]; then
        log "üìã Informaci√≥n del backup:"
        cat "$BACKUP_CONTENT_DIR/backup-info.json" | jq '.' 2>/dev/null || cat "$BACKUP_CONTENT_DIR/backup-info.json"
        echo ""
    fi
    
    # Confirmaci√≥n
    read -p "ü§î ¬øContinuar con la restauraci√≥n? Esto sobrescribir√° datos existentes (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log "‚ùå Restauraci√≥n cancelada"
        cleanup_restore
        exit 1
    fi
    
    # Parar servicios
    log "‚è∏Ô∏è Parando servicios n8n..."
    docker-compose -p $DOCKER_PROJECT down
    
    # Backup de datos actuales (por seguridad)
    if [ -d "$N8N_DATA_DIR" ]; then
        log "üíæ Creando backup de seguridad de datos actuales..."
        mv "$N8N_DATA_DIR" "${N8N_DATA_DIR}.backup.$(date +%s)"
    fi
    
    # Restaurar datos n8n
    if [ -f "$BACKUP_CONTENT_DIR/n8n-data.tar.gz" ]; then
        log "üìÅ Restaurando datos n8n..."
        mkdir -p "$(dirname $N8N_DATA_DIR)"
        tar -xzf "$BACKUP_CONTENT_DIR/n8n-data.tar.gz" -C "$(dirname $N8N_DATA_DIR)"
        
        if [ $? -eq 0 ]; then
            log "‚úÖ Datos n8n restaurados"
        else
            log "‚ùå Error restaurando datos n8n"
            return 1
        fi
    fi
    
    # Restaurar configuraciones
    if [ -f "$BACKUP_CONTENT_DIR/config.tar.gz" ]; then
        log "‚öôÔ∏è Restaurando configuraciones..."
        tar -xzf "$BACKUP_CONTENT_DIR/config.tar.gz" -C "."
        log "‚úÖ Configuraciones restauradas"
    fi
    
    # Restaurar base de datos
    restore_database "$BACKUP_CONTENT_DIR"
    
    # Iniciar servicios
    log "‚ñ∂Ô∏è Iniciando servicios..."
    docker-compose -p $DOCKER_PROJECT up -d
    
    # Verificar que funcione
    log "üîç Verificando funcionamiento..."
    sleep 30
    
    if curl -f http://localhost:5678/healthz &>/dev/null; then
        log "üéâ ¬°Restauraci√≥n exitosa! n8n est√° funcionando"
    else
        log "‚ö†Ô∏è ADVERTENCIA: n8n podr√≠a no estar respondiendo correctamente"
        log "üìù Revisa los logs: docker-compose logs n8n"
    fi
    
    cleanup_restore
}

restore_database() {
    local backup_dir="$1"
    
    # PostgreSQL
    if [ -f "$backup_dir/postgres-dump.sql.gz" ]; then
        log "üóÑÔ∏è Restaurando base de datos PostgreSQL..."
        
        # Esperar a que PostgreSQL est√© listo
        sleep 15
        
        # Restaurar dump
        zcat "$backup_dir/postgres-dump.sql.gz" | docker-compose -p $DOCKER_PROJECT exec -T postgres psql -U n8nuser n8n
        
        if [ ${PIPESTATUS[0]} -eq 0 ]; then
            log "‚úÖ Base de datos PostgreSQL restaurada"
        else
            log "‚ùå Error restaurando PostgreSQL"
        fi
    fi
    
    # MySQL
    if [ -f "$backup_dir/mysql-dump.sql.gz" ]; then
        log "üóÑÔ∏è Restaurando base de datos MySQL..."
        
        sleep 15
        
        zcat "$backup_dir/mysql-dump.sql.gz" | docker-compose -p $DOCKER_PROJECT exec -T mysql mysql -u n8nuser -p n8n
        
        if [ ${PIPESTATUS[0]} -eq 0 ]; then
            log "‚úÖ Base de datos MySQL restaurada"
        else
            log "‚ùå Error restaurando MySQL"
        fi
    fi
}

cleanup_restore() {
    log "üóëÔ∏è Limpiando archivos temporales..."
    rm -rf "$RESTORE_DIR"
}

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Ejecutar restauraci√≥n
restore_backup
```

### üéØ **Restore Selectivo**

```bash
#!/bin/bash
# restore-selective.sh - Restaurar solo componentes espec√≠ficos

restore_workflows_only() {
    local backup_file="$1"
    
    log "üìã Restaurando solo workflows..."
    
    # Extraer y encontrar export de workflows
    TEMP_DIR="/tmp/restore-workflows-$(date +%s)"
    mkdir -p "$TEMP_DIR"
    tar -xzf "$backup_file" -C "$TEMP_DIR"
    
    BACKUP_DIR=$(find "$TEMP_DIR" -mindepth 1 -maxdepth 1 -type d | head -1)
    
    if [ -f "$BACKUP_DIR/workflows-export.json" ]; then
        # Importar workflows usando n8n CLI
        docker cp "$BACKUP_DIR/workflows-export.json" n8n:/tmp/import-workflows.json
        docker-compose exec n8n n8n import:workflow --input="/tmp/import-workflows.json"
        
        log "‚úÖ Workflows restaurados"
    else
        log "‚ùå No se encontr√≥ export de workflows en el backup"
    fi
    
    rm -rf "$TEMP_DIR"
}

restore_credentials_only() {
    local backup_file="$1"
    
    log "üîê Restaurando solo credenciales..."
    
    # Parar n8n
    docker-compose stop n8n
    
    # Extraer y restaurar solo credenciales
    TEMP_DIR="/tmp/restore-creds-$(date +%s)"
    mkdir -p "$TEMP_DIR"
    tar -xzf "$backup_file" -C "$TEMP_DIR"
    
    BACKUP_DIR=$(find "$TEMP_DIR" -mindepth 1 -maxdepth 1 -type d | head -1)
    
    if [ -f "$BACKUP_DIR/n8n-data.tar.gz" ]; then
        # Extraer solo credenciales
        tar -xzf "$BACKUP_DIR/n8n-data.tar.gz" -C "$TEMP_DIR" --wildcards "**/credentials/*"
        
        # Copiar credenciales
        cp -r "$TEMP_DIR/.n8n/credentials/"* "$HOME/.n8n/credentials/"
        
        log "‚úÖ Credenciales restauradas"
    fi
    
    # Reiniciar n8n
    docker-compose start n8n
    
    rm -rf "$TEMP_DIR"
}

# Men√∫ interactivo
echo "üîÑ Restauraci√≥n Selectiva de n8n"
echo "=================================="
echo "1) Solo workflows"
echo "2) Solo credenciales"
echo "3) Solo configuraciones"
echo "4) Restauraci√≥n completa"
echo ""
read -p "Selecciona una opci√≥n [1-4]: " option

case $option in
    1) restore_workflows_only "$1" ;;
    2) restore_credentials_only "$1" ;;
    3) restore_configs_only "$1" ;;
    4) ./restore.sh "$1" ;;
    *) echo "‚ùå Opci√≥n inv√°lida" ;;
esac
```

---

## üß™ Testing de Backups

### üîç **Validaci√≥n de Integridad**

```bash
#!/bin/bash
# test-backup.sh - Validar integridad del backup

test_backup_integrity() {
    local backup_file="$1"
    
    log "üß™ Iniciando test de integridad del backup..."
    
    # Test 1: Verificar que el archivo existe y no est√° corrupto
    if [ ! -f "$backup_file" ]; then
        log "‚ùå Test 1 FAILED: Archivo no existe"
        return 1
    fi
    
    if tar -tzf "$backup_file" >/dev/null 2>&1; then
        log "‚úÖ Test 1 PASSED: Archivo tar √≠ntegro"
    else
        log "‚ùå Test 1 FAILED: Archivo tar corrupto"
        return 1
    fi
    
    # Test 2: Verificar contenidos esperados
    local contents=$(tar -tzf "$backup_file")
    
    if echo "$contents" | grep -q "n8n-data.tar.gz"; then
        log "‚úÖ Test 2 PASSED: Datos n8n presentes"
    else
        log "‚ùå Test 2 FAILED: Datos n8n faltantes"
        return 1
    fi
    
    if echo "$contents" | grep -q "backup-info.json"; then
        log "‚úÖ Test 3 PASSED: Metadata presente"
    else
        log "‚ö†Ô∏è Test 3 WARNING: Metadata faltante"
    fi
    
    # Test 3: Verificar tama√±o razonable
    local size_bytes=$(stat -f%z "$backup_file" 2>/dev/null || stat -c%s "$backup_file")
    local size_mb=$((size_bytes / 1024 / 1024))
    
    if [ $size_mb -gt 1 ] && [ $size_mb -lt 10000 ]; then
        log "‚úÖ Test 4 PASSED: Tama√±o razonable (${size_mb}MB)"
    else
        log "‚ö†Ô∏è Test 4 WARNING: Tama√±o inusual (${size_mb}MB)"
    fi
    
    log "üéâ Tests de integridad completados"
    return 0
}

test_restore_dry_run() {
    local backup_file="$1"
    
    log "üß™ Test de restore (dry run)..."
    
    # Crear entorno temporal
    TEMP_ENV="/tmp/n8n-test-$(date +%s)"
    mkdir -p "$TEMP_ENV"
    cd "$TEMP_ENV"
    
    # Extraer backup
    tar -xzf "$backup_file"
    BACKUP_DIR=$(find . -mindepth 1 -maxdepth 1 -type d | head -1)
    
    # Verificar componentes
    local score=0
    local total=0
    
    # Test datos n8n
    total=$((total + 1))
    if [ -f "$BACKUP_DIR/n8n-data.tar.gz" ]; then
        if tar -tzf "$BACKUP_DIR/n8n-data.tar.gz" | grep -q "workflows"; then
            log "‚úÖ Datos n8n v√°lidos"
            score=$((score + 1))
        else
            log "‚ùå Datos n8n inv√°lidos"
        fi
    fi
    
    # Test configuraci√≥n
    total=$((total + 1))
    if [ -f "$BACKUP_DIR/config.tar.gz" ]; then
        if tar -tzf "$BACKUP_DIR/config.tar.gz" | grep -q "docker-compose.yml"; then
            log "‚úÖ Configuraci√≥n v√°lida"
            score=$((score + 1))
        else
            log "‚ùå Configuraci√≥n inv√°lida"
        fi
    fi
    
    # Test base de datos
    total=$((total + 1))
    if [ -f "$BACKUP_DIR/postgres-dump.sql.gz" ] || [ -f "$BACKUP_DIR/mysql-dump.sql.gz" ]; then
        log "‚úÖ Backup de BD presente"
        score=$((score + 1))
    else
        log "‚ÑπÔ∏è No hay backup de BD (SQLite en uso)"
        score=$((score + 1))  # No penalizar si usa SQLite
    fi
    
    # Cleanup
    cd /
    rm -rf "$TEMP_ENV"
    
    # Resultado
    local percentage=$((score * 100 / total))
    log "üìä Score del backup: $score/$total ($percentage%)"
    
    if [ $percentage -ge 80 ]; then
        log "üéâ Backup V√ÅLIDO para restore"
        return 0
    else
        log "‚ùå Backup NO RECOMENDADO para restore"
        return 1
    fi
}

# Script principal de testing
if [ -z "$1" ]; then
    echo "Uso: $0 <backup-file.tar.gz>"
    exit 1
fi

test_backup_integrity "$1"
test_restore_dry_run "$1"
```

### üéØ **Test de Restore Completo**

```bash
#!/bin/bash
# test-full-restore.sh - Test completo de restauraci√≥n en entorno aislado

test_full_restore() {
    local backup_file="$1"
    local test_name="test-$(date +%s)"
    
    log "üß™ Iniciando test completo de restore..."
    
    # Crear entorno de test aislado
    local test_dir="/tmp/n8n-restore-test-$test_name"
    mkdir -p "$test_dir"
    cd "$test_dir"
    
    # Copiar configuraci√≥n base
    cp /opt/n8n-production/docker-compose.yml .
    cp /opt/n8n-production/.env .env.test
    
    # Modificar configuraci√≥n para test
    sed -i 's/n8n-production/n8n-test-'$test_name'/g' docker-compose.yml
    sed -i 's/5678:5678/5679:5678/g' docker-compose.yml  # Usar puerto diferente
    
    # Ejecutar restore en entorno de test
    COMPOSE_PROJECT_NAME="n8n-test-$test_name" ./restore.sh "$backup_file"
    
    # Verificar que el restore funcion√≥
    sleep 30
    
    if curl -f http://localhost:5679/healthz &>/dev/null; then
        log "‚úÖ Test de restore EXITOSO"
        
        # Tests adicionales
        test_workflows_loadable
        test_credentials_loadable
        
        result=0
    else
        log "‚ùå Test de restore FALLIDO"
        result=1
    fi
    
    # Cleanup del entorno de test
    cd /tmp
    docker-compose -f "$test_dir/docker-compose.yml" -p "n8n-test-$test_name" down -v
    rm -rf "$test_dir"
    
    return $result
}

test_workflows_loadable() {
    log "üß™ Testing workflows cargables..."
    
    # Obtener lista de workflows via API
    local response=$(curl -s http://localhost:5679/api/v1/workflows 2>/dev/null)
    
    if echo "$response" | grep -q '"data"'; then
        local count=$(echo "$response" | jq '.data | length' 2>/dev/null || echo "0")
        log "‚úÖ $count workflows cargados exitosamente"
    else
        log "‚ùå Error cargando workflows"
    fi
}
```

---

## üìä Monitoreo y Alertas

### üìà **Monitor de Backups**

```bash
#!/bin/bash
# monitor-backups.sh - Monitoreo de estado de backups

BACKUP_DIR="/backups/n8n"
MAX_AGE_HOURS=25  # M√°ximo tiempo sin backup
LOG_FILE="/var/log/backup-monitor.log"

check_backup_status() {
    log "üîç Verificando estado de backups..."
    
    # Encontrar backup m√°s reciente
    local latest_backup=$(ls -t "$BACKUP_DIR"/n8n-backup-*.tar.gz 2>/dev/null | head -1)
    
    if [ -z "$latest_backup" ]; then
        notify "CR√çTICO: No se encontraron backups" "ERROR"
        return 1
    fi
    
    # Verificar edad del backup
    local backup_time=$(stat -c %Y "$latest_backup")
    local current_time=$(date +%s)
    local age_hours=$(( (current_time - backup_time) / 3600 ))
    
    if [ $age_hours -gt $MAX_AGE_HOURS ]; then
        notify "ADVERTENCIA: √öltimo backup tiene $age_hours horas (m√°x: $MAX_AGE_HOURS)" "WARNING"
    else
        log "‚úÖ Backup reciente encontrado ($age_hours horas)"
    fi
    
    # Verificar integridad del √∫ltimo backup
    if tar -tzf "$latest_backup" >/dev/null 2>&1; then
        log "‚úÖ Backup √≠ntegro"
    else
        notify "CR√çTICO: √öltimo backup est√° corrupto" "ERROR"
        return 1
    fi
    
    # Verificar espacio en disco
    local available_gb=$(df "$BACKUP_DIR" | awk 'NR==2 {print int($4/1024/1024)}')
    if [ $available_gb -lt 5 ]; then
        notify "ADVERTENCIA: Poco espacio en disco: ${available_gb}GB" "WARNING"
    fi
    
    # Estad√≠sticas
    local total_backups=$(ls "$BACKUP_DIR"/n8n-backup-*.tar.gz 2>/dev/null | wc -l)
    local total_size=$(du -sh "$BACKUP_DIR" 2>/dev/null | cut -f1)
    
    log "üìä Total backups: $total_backups, Espacio usado: $total_size"
    
    return 0
}

generate_backup_report() {
    log "üìã Generando reporte de backups..."
    
    local report_file="/tmp/backup-report-$(date +%Y%m%d).txt"
    
    cat > "$report_file" << EOF
# Reporte de Backups n8n
## Generado: $(date)

### Estado General
- √öltimo backup: $(ls -t "$BACKUP_DIR"/n8n-backup-*.tar.gz 2>/dev/null | head -1 | xargs basename)
- Edad: $(( ($(date +%s) - $(stat -c %Y $(ls -t "$BACKUP_DIR"/n8n-backup-*.tar.gz 2>/dev/null | head -1))) / 3600 )) horas
- Total backups: $(ls "$BACKUP_DIR"/n8n-backup-*.tar.gz 2>/dev/null | wc -l)
- Espacio usado: $(du -sh "$BACKUP_DIR" 2>/dev/null | cut -f1)

### Backups Recientes
EOF
    
    # Listar √∫ltimos 10 backups
    ls -lt "$BACKUP_DIR"/n8n-backup-*.tar.gz 2>/dev/null | head -10 | while read -r line; do
        echo "- $line" >> "$report_file"
    done
    
    echo "üìã Reporte generado: $report_file"
}

# Ejecutar monitoring
check_backup_status
generate_backup_report
```

### üö® **Alertas Inteligentes**

```bash
#!/bin/bash
# smart-alerts.sh - Sistema de alertas inteligente

# Configuraci√≥n de alertas
ALERT_CONFIG="/etc/n8n-backup-alerts.conf"

# Crear configuraci√≥n por defecto si no existe
if [ ! -f "$ALERT_CONFIG" ]; then
    cat > "$ALERT_CONFIG" << 'EOF'
# Configuraci√≥n de alertas n8n backup
BACKUP_MAX_AGE_HOURS=25
DISK_WARNING_THRESHOLD=5  # GB
DISK_CRITICAL_THRESHOLD=2  # GB
BACKUP_SIZE_MIN_MB=50
BACKUP_SIZE_MAX_MB=5000
CONSECUTIVE_FAILURES_CRITICAL=3
EMAIL_ALERTS=true
SLACK_ALERTS=false
TELEGRAM_ALERTS=false
EOF
fi

source "$ALERT_CONFIG"

send_alert() {
    local message="$1"
    local level="$2"  # INFO, WARNING, ERROR, CRITICAL
    local component="$3"  # backup, disk, network, etc.
    
    # Log local
    log "[$level] $component: $message"
    
    # Email
    if [ "$EMAIL_ALERTS" = "true" ] && [ ! -z "$NOTIFY_EMAIL" ]; then
        echo "$message" | mail -s "n8n Backup Alert [$level]" "$NOTIFY_EMAIL"
    fi
    
    # Slack
    if [ "$SLACK_ALERTS" = "true" ] && [ ! -z "$SLACK_WEBHOOK" ]; then
        local emoji
        case $level in
            INFO) emoji=":information_source:" ;;
            WARNING) emoji=":warning:" ;;
            ERROR) emoji=":x:" ;;
            CRITICAL) emoji=":rotating_light:" ;;
        esac
        
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"$emoji n8n Backup [$level]: $message\"}" \
            "$SLACK_WEBHOOK" 2>/dev/null
    fi
    
    # Telegram
    if [ "$TELEGRAM_ALERTS" = "true" ] && [ ! -z "$TELEGRAM_BOT_TOKEN" ] && [ ! -z "$TELEGRAM_CHAT_ID" ]; then
        curl -s "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendMessage" \
            -d chat_id="$TELEGRAM_CHAT_ID" \
            -d text="üîÑ n8n Backup [$level]: $message"
    fi
}

check_backup_health() {
    local issues=0
    
    # Verificar edad del backup
    local latest_backup=$(ls -t "$BACKUP_DIR"/n8n-backup-*.tar.gz 2>/dev/null | head -1)
    if [ ! -z "$latest_backup" ]; then
        local backup_age_hours=$(( ($(date +%s) - $(stat -c %Y "$latest_backup")) / 3600 ))
        
        if [ $backup_age_hours -gt $BACKUP_MAX_AGE_HOURS ]; then
            send_alert "√öltimo backup muy antiguo: $backup_age_hours horas" "WARNING" "backup"
            issues=$((issues + 1))
        fi
    else
        send_alert "No se encontraron backups" "CRITICAL" "backup"
        return 1
    fi
    
    # Verificar espacio en disco
    local available_gb=$(df "$BACKUP_DIR" | awk 'NR==2 {print int($4/1024/1024)}')
    
    if [ $available_gb -le $DISK_CRITICAL_THRESHOLD ]; then
        send_alert "CR√çTICO: Espacio en disco: ${available_gb}GB" "CRITICAL" "disk"
        issues=$((issues + 1))
    elif [ $available_gb -le $DISK_WARNING_THRESHOLD ]; then
        send_alert "Poco espacio en disco: ${available_gb}GB" "WARNING" "disk"
    fi
    
    # Verificar tama√±o del backup
    local backup_size_mb=$(du -m "$latest_backup" | cut -f1)
    
    if [ $backup_size_mb -lt $BACKUP_SIZE_MIN_MB ]; then
        send_alert "Backup suspiciosamente peque√±o: ${backup_size_mb}MB" "WARNING" "backup"
        issues=$((issues + 1))
    elif [ $backup_size_mb -gt $BACKUP_SIZE_MAX_MB ]; then
        send_alert "Backup muy grande: ${backup_size_mb}MB" "INFO" "backup"
    fi
    
    # Verificar tendencia de fallos
    local recent_failures=$(grep "ERROR\|FAILED" "$LOG_FILE" | tail -20 | wc -l)
    if [ $recent_failures -ge $CONSECUTIVE_FAILURES_CRITICAL ]; then
        send_alert "M√∫ltiples fallos recientes: $recent_failures" "CRITICAL" "backup"
    fi
    
    if [ $issues -eq 0 ]; then
        send_alert "Todos los sistemas de backup funcionando correctamente" "INFO" "status"
    fi
    
    return $issues
}

# Configurar cron para alertas
# 0 */6 * * * /opt/smart-alerts.sh
check_backup_health
```

---

## ‚úÖ Checklist Backup Completo

### üéØ **Implementaci√≥n Exitosa**

- [ ] ‚úÖ **Backup manual** funcionando
- [ ] ‚úÖ **Backup automatizado** configurado
- [ ] ‚úÖ **Backup en la nube** activo
- [ ] ‚úÖ **Script de restore** probado
- [ ] ‚úÖ **Testing de integridad** implementado
- [ ] ‚úÖ **Monitoreo** configurado
- [ ] ‚úÖ **Alertas** activadas
- [ ] ‚úÖ **Documentaci√≥n** actualizada
- [ ] ‚úÖ **Cronograma 3-2-1** seguido
- [ ] ‚úÖ **Restore probado** en entorno aislado

### üìä **M√©tricas de Backup**

```bash
# Script de m√©tricas
echo "üìä Estad√≠sticas de Backup n8n"
echo "============================="
echo "√öltimo backup: $(ls -t /backups/n8n/n8n-backup-*.tar.gz | head -1 | xargs basename)"
echo "Edad: $(( ($(date +%s) - $(stat -c %Y $(ls -t /backups/n8n/n8n-backup-*.tar.gz | head -1))) / 3600 )) horas"
echo "Total backups: $(ls /backups/n8n/n8n-backup-*.tar.gz 2>/dev/null | wc -l)"
echo "Espacio usado: $(du -sh /backups/n8n | cut -f1)"
echo "Espacio disponible: $(df -h /backups | awk 'NR==2 {print $4}')"
```

---

## üö® Plan de Recuperaci√≥n ante Desastres

### üî• **Escenarios de Emergencia**

1. **üñ•Ô∏è Fallo completo del servidor**
   - Tiempo de recuperaci√≥n: 2-4 horas
   - Backup necesario: Completo + Configuraci√≥n
   - Acci√≥n: Restaurar en nuevo servidor

2. **üíæ Corrupci√≥n de datos**
   - Tiempo de recuperaci√≥n: 30-60 minutos
   - Backup necesario: Datos + DB
   - Acci√≥n: Restore selectivo

3. **ü¶† Ataque malware/ransomware**
   - Tiempo de recuperaci√≥n: 1-8 horas
   - Backup necesario: Completo offline
   - Acci√≥n: Servidor limpio + Restore

4. **‚òÅÔ∏è Fallo del proveedor VPS**
   - Tiempo de recuperaci√≥n: 1-24 horas
   - Backup necesario: Multi-cloud
   - Acci√≥n: Migrar a proveedor alternativo

---

> **üíæ ¬°Perfecto!** Tu estrategia de backup es robusta y completa. Tus datos est√°n seguros y puedes dormir tranquilo sabiendo que puedes recuperar tu n8n en cualquier momento.

**üí° Tip Final**: Un backup no probado es como no tener backup. Prueba tus restores regularmente - preferiblemente en un entorno separado cada mes.